# ----------------------------------------
# Makefile for wbphenotype
# Generated using ontology-starter-kit
# ----------------------------------------
# <do not edit above this line>

# ----------------------------------------
# Standard Constants
# ----------------------------------------
# these can be overwritten on the command line

OBO=http://purl.obolibrary.org/obo
ONT=wbphenotype
BASE=$(OBO)/$(ONT)
SRC=$(ONT)-edit.owl
RELEASEDIR=../..
ROBOT= robot
OWLTOOLS= owltools
USECAT= --use-catalog
SPARQLDIR = ../sparql
DOSDP_SCHEMA=http:// # change to PURL when ready.
PATTERN_TESTER=simple_pattern_tester.py
DOSDPT=dosdp-tools
TARGET=target
IMPORTS = iao ro pato bfo wbbt wbls chebi go cl
# chebi go cl

# ----------------------------------------
# Top-level targets
# ----------------------------------------

all: all_imports patterns sparql_test $(ONT).owl $(ONT).obo $(ONT)-base.owl $(ONT)-merged.owl $(ONT)-merged.obo
	echo 'Release files created successfully.'
test: sparql_test all
prepare_release: all
	cp $(ONT).owl $(ONT).obo $(ONT)-base.owl $(ONT)-merged.owl $(ONT)-merged.obo $(RELEASEDIR) &&\
	cp wbphenotype-equivalent-axioms-subq.owl $(RELEASEDIR) &&\
	mkdir -p $(RELEASEDIR)/imports &&\
	mkdir -p $(RELEASEDIR)/patterns &&\
	cp imports/*.owl $(RELEASEDIR)/imports &&\
	cp imports/*.obo $(RELEASEDIR)/imports &&\
	cp ../patterns/definitions.owl $(RELEASEDIR)/patterns &&\
	git add $(RELEASEDIR)/imports/*.obo &&\
	git add $(RELEASEDIR)/imports/*.owl &&\
	git add $(RELEASEDIR)/patterns/*.owl &&\
	(test -f subsets/*owl && cp subsets/* $(RELEASEDIR)/subsets && git add $(RELEASEDIR)/subsets/* || echo "no subsets") &&\
	echo "Release files are now in $(RELEASEDIR) - now you should commit, push and make a release on github"

# ----------------------------------------
# Main release targets
# ----------------------------------------

# by default we use Elk to perform a reason-relax-reduce chain
# after that we annotate the ontology with the release versionInfo
# Equivalence checking deactived.. -e none
$(ONT).owl: $(SRC)
	$(ROBOT)  reason -i $< -r ELK relax reduce -r ELK annotate -V $(BASE)/releases/`date +%Y-%m-%d`/$(ONT).owl -o $@

$(ONT).obo: $(ONT).owl
	$(ROBOT) convert --check false -i $< -f obo -o $(ONT).obo.tmp && mv $(ONT).obo.tmp $@ 

$(ONT)-base.owl: $(SRC) ../patterns/definitions.owl
	$(ROBOT) remove --input $< --select imports --output $@ &&\
	$(ROBOT) merge -i $@ -i ../patterns/definitions.owl annotate -V $(BASE)/releases/`date +%Y-%m-%d`/$(ONT)-base.owl annotate --ontology-iri $(BASE)/$(ONT)-base.owl -o $@	

$(ONT)-merged.owl: $(ONT).owl
	$(ROBOT) merge -i $< annotate -V $(BASE)/releases/`date +%Y-%m-%d`/$(ONT)-merged.owl annotate --ontology-iri $(BASE)/$(ONT)-merged.owl -o $@ 
	
$(ONT)-merged.obo: $(ONT)-merged.owl
	$(ROBOT) convert --check false -i $< -f obo -o $(ONT)-merged.obo.tmp && mv $(ONT)-merged.obo.tmp $@ 

# ----------------------------------------
# Import modules
# ----------------------------------------
# Most ontologies are modularly constructed using portions of other ontologies
# These live in the imports/ folder
# These can be regenerated with make all_imports

IMPORTS_OWL = $(patsubst %, imports/%_import.owl,$(IMPORTS)) $(patsubst %, imports/%_import.obo,$(IMPORTS)) $(patsubst %, imports/%_terms.txt,$(IMPORTS))

# generate seed with all referenced entities

seed.txt: $(SRC) all_pattern_terms.txt
	$(ROBOT) query --use-graphs true -f csv -i $< --query ../sparql/terms.sparql seed.txt.tmp &&\
	cat seed.txt.tmp all_pattern_terms.txt | sort | uniq >  $@

# Generate terms.txt for each import.  # Assume OBO-style Possibly hacky step?
# Should be able to drop this if robot can just take a big messy list of terms as input.

imports/%_terms_combined.txt: seed.txt
	cat $< imports/$*_terms.txt | sort | uniq >  $@

# Make this target to regenerate ALL
all_imports: $(IMPORTS_OWL)

# Use ROBOT, driven entirely by terms lists NOT from source ontology
imports/%_import.owl: mirror/%.owl imports/%_terms_combined.txt
	$(ROBOT) extract -i $< -T imports/$*_terms_combined.txt --method BOT -O $(BASE)/$@ -o $@
.PRECIOUS: imports/%_import.owl

# convert imports to obo.
# this can be useful for spot-checks and diffs.
# we set strict mode to false by default. For discussion see https://github.com/owlcs/owlapi/issues/752
imports/%_import.obo: imports/%_import.owl
	$(ROBOT) convert --check false -i $< -f obo -o $@.tmp && mv $@.tmp $@

# clone remote ontology locally, perfoming some excision of relations and annotations

mirror/%.owl:
	mkdir -p mirror && wget -O $@ $(OBO)/$*.owl
	#$(ROBOT) convert -I $@ -o $@
.PRECIOUS: mirror/%.owl

# ----------------------------------------
# Release
# ----------------------------------------
# copy from staging area (this directory) to top-level
release: $(ONT).owl $(ONT).obo $(ONT)-base.owl $(ONT)-merged.owl $(ONT)-merged.obo
	cp $^ $(RELEASEDIR) && cp imports/* $(RELEASEDIR)/imports

# ----------------------------------------
# Sparql queries: Q/C
# ----------------------------------------

# these live in the ../sparql directory, and have suffix -violation.sparql
# adding the name here will make the violation check live
#   equivalent-classes
VCHECKS =  owldef-self-reference trailing-whitespace xref-syntax nolabels

# Only needed until robot supports catalogs



#  run all violation checks
VQUERIES = $(foreach V,$(VCHECKS),$(SPARQLDIR)/$V-violation.sparql)
sparql_test: $(SRC)
	robot verify  --catalog catalog-v001.xml -i $< --queries $(VQUERIES) -O reports/

# ----------------------------------------
# Sparql queries: Reports
 # ----------------------------------------

REPORTS = basic-report class-count-by-prefix edges xrefs obsoletes synonyms
REPORT_ARGS = $(foreach V,$(REPORTS),-s $(SPARQLDIR)/$V.sparql reports/$V.tsv)
all_reports: $(SRC)
	robot query -f tsv -i $< $(REPORT_ARGS)

# ----------------------------------------
# Docker (experimental)
# ----------------------------------------
IM=build-$(ONT)
build-docker:
	docker build -t $(ONT) .

	# ----------------------------------------
	# Patterns (experimental)
	# ----------------------------------------

	# ----------------------------------------
	# Main command to generate the pattern ontology and the definitions
	# ----------------------------------------
	# The pattern.owl ontology contains the OWL versions of all the patterns currently in the patterns directory

.PHONY: .FORCE

.PHONY patterns: ../patterns/pattern.owl ../patterns/definitions.owl

pattern_clean:
	echo "Not implemented"

	# ----------------------------------------
	# Build pattern.owl
	# ----------------------------------------
	# The pattern.owl ontology contains the OWL versions of all the patterns currently in the patterns directory

pattern_schema_checks: ../patterns/dosdp-patterns
	simple_pattern_tester.py ../patterns/dosdp-patterns/ # 2>&1 | tee $@

#This command is a workaround for the absence of -N and -i in wget of alpine (the one ODK depend on now). It downloads all patterns specified in external.txt
../patterns/dosdp-patterns: .FORCE
	< ../patterns/dosdp-patterns/external.txt tr '\n' '\0' | sed 's!.*/!!' | xargs -0 -I{} rm ../patterns/dosdp-patterns/{} &&\
	< ../patterns/dosdp-patterns/external.txt tr '\n' '\0' | xargs -0 -I{} wget -q {} -P ../patterns/dosdp-patterns

../patterns/pattern.owl: pattern_schema_checks ../patterns/dosdp-patterns
	$(DOSDPT) prototype --obo-prefixes --template=../patterns/dosdp-patterns --outfile=$@


	# ----------------------------------------
	# Build definitions.owl
	# ----------------------------------------
	# The following target will create a merged version of all imports indicated as project import dependencies (including the edit file itself), and then extract a module based
	# on the entities used in the TSV files
individual_patterns_manual := $(patsubst %.tsv, ../patterns/data/manual/%.ofn, $(notdir $(wildcard ../patterns/data/manual/*.tsv)))
individual_patterns_auto := $(patsubst %.tsv, ../patterns/data/auto/%.ofn, $(notdir $(wildcard ../patterns/data/auto/*.tsv)))
pattern_term_lists_auto := $(patsubst %.tsv, ../patterns/data/auto/%.txt, $(notdir $(wildcard ../patterns/data/auto/*.tsv)))
pattern_term_lists_manual := $(patsubst %.tsv, ../patterns/data/manual/%.txt, $(notdir $(wildcard ../patterns/data/manual/*.tsv)))

../patterns/definitions.owl: $(individual_patterns_manual) $(individual_patterns_auto)
	$(ROBOT) merge $(addprefix -i , $(individual_patterns_manual)) $(addprefix -i , $(individual_patterns_auto)) annotate --ontology-iri $(OBO)/$(ONT)/patterns/definitions.owl -o definitions.ofn &&\
	mv definitions.ofn $@

../patterns/data/manual/%.ofn: ../patterns/data/manual/%.tsv ../patterns/dosdp-patterns/%.yaml $(SRC) all_imports
	dosdp-tools generate --catalog=catalog-v001.xml --infile=$< --template=$(word 2, $^) --ontology=$(word 3, $^) --obo-prefixes=true --restrict-axioms-to=logical --outfile=$@

../patterns/data/auto/%.ofn: ../patterns/data/auto/%.tsv ../patterns/dosdp-patterns/%.yaml $(SRC) all_imports
	dosdp-tools generate --catalog=catalog-v001.xml --infile=$< --template=$(word 2, $^) --ontology=$(word 3, $^) --obo-prefixes=true --restrict-axioms-to=logical --outfile=$@

# Generating the seed file from all the TSVs
all_pattern_terms.txt: $(pattern_term_lists_auto) $(pattern_term_lists_manual) pattern_owl_seed.txt
	cat $^ | sort | uniq > $@
	
pattern_owl_seed.txt: ../patterns/pattern.owl
	$(ROBOT) query --use-graphs true -f csv -i $< --query ../sparql/terms.sparql $@

../patterns/data/manual/%.txt: ../patterns/dosdp-patterns/%.yaml ../patterns/data/manual/%.tsv
	dosdp-tools terms --infile=$(word 2, $^) --template=$< --obo-prefixes=true --outfile=$@

../patterns/data/auto/%.txt: ../patterns/dosdp-patterns/%.yaml ../patterns/data/auto/%.tsv
	dosdp-tools terms --infile=$(word 2, $^) --template=$< --obo-prefixes=true --outfile=$@

labels.csv:
	robot query --use-graphs true -f csv -i $(SRC) --query ../sparql/term_table.sparql $@
